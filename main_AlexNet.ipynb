{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Introduction of Deep Learning for Computer Vision \n",
    "### Computer Vision and Machine Learning Research Group, Shenzhen University, 2019 Dec."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Network Structure: AlexNet  \n",
    "Dataset: cifar-10 or ImageNet  \n",
    "Instructor: Yan Yan  \n",
    "Email: yyan@szu.edu.cn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Referece: ImageNet Classification with Deep Convolutional Neural, Alex Krizhevsky, Sutskever, Ilya, Hinton, Geoffrey E, Advances in Neural Information Processing Systems 25, pp.1097--1105, 2012\n",
    "[Download Link](\n",
    "http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)  \n",
    "\n",
    "Code is mostly based on:  \n",
    "https://www.cnblogs.com/zhengbiqing/p/10425503.html  contact：zhengbiqing 460356155@qq.com  \n",
    "and  \n",
    "https://blog.csdn.net/yychentracy/article/details/90256033  \n",
    "and  \n",
    "https://github.com/sloth2012/AlexNet/blob/master/AlexNet.ipynb\n",
    "  \n",
    "Dataset can be downloaded from:\n",
    "http://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torchvision as tv\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToPILImage\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import datetime\n",
    "import argparse\n",
    "\n",
    "\n",
    "# 样本读取线程数\n",
    "WORKERS = 4\n",
    "\n",
    "# 网络参赛保存文件名\n",
    "PARAS_FN = 'cifar_lenet_params.pkl'\n",
    "\n",
    "# minist数据存放位置\n",
    "ROOT = '/home/szu-admin/local/data/cifar-10-100/cifar.10.py'\n",
    "\n",
    "# 目标函数\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# 最优结果\n",
    "best_acc = 0\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNet, self).__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            # 卷积层1，3通道输入，96个卷积核，核大小7*7，步长2，填充2\n",
    "            # 经过该层图像大小变为32-7+2*2 / 2 +1，15*15\n",
    "            # 经3*3最大池化，2步长，图像变为15-3 / 2 + 1， 7*7\n",
    "            nn.Conv2d(3, 96, 7, 2, 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(3, 2, 0),\n",
    "\n",
    "            # 卷积层2，96输入通道，256个卷积核，核大小5*5，步长1，填充2\n",
    "            # 经过该层图像变为7-5+2*2 / 1 + 1，7*7\n",
    "            # 经3*3最大池化，2步长，图像变为7-3 / 2 + 1， 3*3\n",
    "            nn.Conv2d(96, 256, 5, 1, 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(3, 2, 0),\n",
    "\n",
    "            # 卷积层3，256输入通道，384个卷积核，核大小3*3，步长1，填充1\n",
    "            # 经过该层图像变为3-3+2*1 / 1 + 1，3*3\n",
    "            nn.Conv2d(256, 384, 3, 1, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # 卷积层3，384输入通道，384个卷积核，核大小3*3，步长1，填充1\n",
    "            # 经过该层图像变为3-3+2*1 / 1 + 1，3*3\n",
    "            nn.Conv2d(384, 384, 3, 1, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # 卷积层3，384输入通道，256个卷积核，核大小3*3，步长1，填充1\n",
    "            # 经过该层图像变为3-3+2*1 / 1 + 1，3*3\n",
    "            nn.Conv2d(384, 256, 3, 1, 1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            # 256个feature，每个feature 3*3\n",
    "            nn.Linear(256*3*3, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "\n",
    "        # x.size()[0]: batch size\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    \n",
    "'''\n",
    "训练并测试网络\n",
    "net：网络模型\n",
    "train_data_load：训练数据集\n",
    "optimizer：优化器\n",
    "epoch：第几次训练迭代\n",
    "log_interval：训练过程中损失函数值和准确率的打印频率\n",
    "'''\n",
    "def net_train(net, train_data_load, optimizer, epoch, log_interval):\n",
    "    net.train()\n",
    "\n",
    "    begin = datetime.datetime.now()\n",
    "\n",
    "    # 样本总数\n",
    "    total = len(train_data_load.dataset)\n",
    "\n",
    "    # 样本批次训练的损失函数值的和\n",
    "    train_loss = 0\n",
    "\n",
    "    # 识别正确的样本数\n",
    "    ok = 0\n",
    "\n",
    "    for i, data in enumerate(train_data_load, 0):\n",
    "        img, label = data\n",
    "        img, label = img.cuda(), label.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outs = net(img)\n",
    "        loss = loss_func(outs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 累加损失值和训练样本数\n",
    "        train_loss += loss.item()\n",
    "        # total += label.size(0)\n",
    "\n",
    "        _, predicted = t.max(outs.data, 1)\n",
    "        # 累加识别正确的样本数\n",
    "        ok += (predicted == label).sum()\n",
    "\n",
    "        if (i + 1) % log_interval == 0:\n",
    "            # 训练结果输出\n",
    "\n",
    "            # 损失函数均值\n",
    "            loss_mean = train_loss / (i + 1)\n",
    "\n",
    "            # 已训练的样本数\n",
    "            traind_total = (i + 1) * len(label)\n",
    "\n",
    "            # 准确度\n",
    "            acc = 100. * ok / traind_total\n",
    "\n",
    "            # 一个迭代的进度百分比\n",
    "            progress = 100. * traind_total / total\n",
    "\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}  Acc: {:.6f}'.format(\n",
    "                epoch, traind_total, total, progress, loss_mean, acc))\n",
    "\n",
    "    end = datetime.datetime.now()\n",
    "    print('one epoch spend: ', end - begin)\n",
    "\n",
    "\n",
    "'''\n",
    "用测试集检查准确率\n",
    "'''\n",
    "def net_test(net, test_data_load, epoch):\n",
    "    net.eval()\n",
    "\n",
    "    ok = 0\n",
    "\n",
    "    for i, data in enumerate(test_data_load):\n",
    "        img, label = data\n",
    "        img, label = img.cuda(), label.cuda()\n",
    "\n",
    "        outs = net(img)\n",
    "        _, pre = t.max(outs.data, 1)\n",
    "        ok += (pre == label).sum()\n",
    "\n",
    "    acc = ok.item() * 100. / (len(test_data_load.dataset))\n",
    "    print('EPOCH:{}, ACC:{}\\n'.format(epoch, acc))\n",
    "\n",
    "    global best_acc\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "\n",
    "\n",
    "'''\n",
    "显示数据集中一个图片\n",
    "'''\n",
    "def img_show(dataset, index):\n",
    "    classes = ('plane', 'car', 'bird', 'cat',\n",
    "               'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "    show = ToPILImage()\n",
    "\n",
    "    data, label = dataset[index]\n",
    "    print('img is a ', classes[label])\n",
    "    show((data + 1) / 2).resize((100, 100)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#parser = argparse.ArgumentParser(description='PyTorch CIFA10 LeNet Example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 训练超参数设置，可通过命令行设置\n",
    "bs = 64            # batch-size\n",
    "testbs = 1000      # test-batch-size\n",
    "ep = 20            # epochs \n",
    "trainlr = 0.01     # learning rate (default: 0.01)\n",
    "mm = 0.9           # SGD momentum (default: 0.9)\n",
    "logint = 100       # log-interval\n",
    "notrain = False    # If train the Model\n",
    "savemodel = False  # For Saving the current Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 图像数值转换，ToTensor源码注释\n",
    "\"\"\"\n",
    "Convert a ``PIL Image`` or ``numpy.ndarray`` to tensor.\n",
    "Converts a PIL Image or numpy.ndarray (H x W x C) in the range\n",
    "[0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0].\n",
    "\"\"\"\n",
    "# 归一化把[0.0, 1.0]变换为[-1,1], ([0, 1] - 0.5) / 0.5 = [-1, 1]\n",
    "transform = tv.transforms.Compose([\n",
    "transforms.ToTensor(),\n",
    "transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
    "\n",
    "# 定义数据集\n",
    "#train_data = tv.datasets.CIFAR10(root=ROOT, train=True, download=True, transform=transform)\n",
    "train_data = tv.datasets.CIFAR10(root=ROOT, train=True, download=False, transform=transform)\n",
    "test_data = tv.datasets.CIFAR10(root=ROOT, train=False, download=False, transform=transform)\n",
    "\n",
    "train_load = t.utils.data.DataLoader(train_data, batch_size=bs, shuffle=True, num_workers=WORKERS)\n",
    "test_load = t.utils.data.DataLoader(test_data, batch_size=testbs, shuffle=False, num_workers=WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1aa6072eb8>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 看一下数据中的等待分类的图片\n",
    "from PIL import Image\n",
    "import sys\n",
    "#im = Image.open(train_data.data[5][0])\n",
    "im = Image.fromarray(train_data.data[5][:])\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (cnn): Sequential(\n",
      "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace)\n",
      "    (8): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace)\n",
      "    (10): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=2304, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# define AlexNet\n",
    "net = AlexNet().cuda()\n",
    "# print network structure\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 0.050328  Acc: 98.000000\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 0.054780  Acc: 98.000000\n",
      "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 0.061450  Acc: 97.000000\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 0.059535  Acc: 97.000000\n",
      "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 0.060373  Acc: 97.000000\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 0.068226  Acc: 97.000000\n",
      "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 0.067621  Acc: 97.000000\n",
      "one epoch spend:  0:00:05.983943\n",
      "EPOCH:1, ACC:75.66\n",
      "\n",
      "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 0.038682  Acc: 98.000000\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 0.038624  Acc: 98.000000\n",
      "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 0.040471  Acc: 98.000000\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 0.045076  Acc: 98.000000\n",
      "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 0.048262  Acc: 98.000000\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 0.048755  Acc: 98.000000\n",
      "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 0.050158  Acc: 98.000000\n",
      "one epoch spend:  0:00:05.961413\n",
      "EPOCH:2, ACC:75.26\n",
      "\n",
      "Train Epoch: 3 [6400/50000 (13%)]\tLoss: 0.054477  Acc: 98.000000\n",
      "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 0.050144  Acc: 98.000000\n",
      "Train Epoch: 3 [19200/50000 (38%)]\tLoss: 0.047142  Acc: 98.000000\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 0.046300  Acc: 98.000000\n",
      "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 0.048714  Acc: 98.000000\n",
      "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 0.047779  Acc: 98.000000\n",
      "Train Epoch: 3 [44800/50000 (90%)]\tLoss: 0.049408  Acc: 98.000000\n",
      "one epoch spend:  0:00:05.881938\n",
      "EPOCH:3, ACC:76.15\n",
      "\n",
      "Train Epoch: 4 [6400/50000 (13%)]\tLoss: 0.036894  Acc: 98.000000\n",
      "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 0.041849  Acc: 98.000000\n",
      "Train Epoch: 4 [19200/50000 (38%)]\tLoss: 0.041304  Acc: 98.000000\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 0.042353  Acc: 98.000000\n",
      "Train Epoch: 4 [32000/50000 (64%)]\tLoss: 0.044223  Acc: 98.000000\n",
      "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 0.050764  Acc: 98.000000\n",
      "Train Epoch: 4 [44800/50000 (90%)]\tLoss: 0.051771  Acc: 98.000000\n",
      "one epoch spend:  0:00:06.059588\n",
      "EPOCH:4, ACC:76.24\n",
      "\n",
      "Train Epoch: 5 [6400/50000 (13%)]\tLoss: 0.028199  Acc: 99.000000\n",
      "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 0.036868  Acc: 98.000000\n",
      "Train Epoch: 5 [19200/50000 (38%)]\tLoss: 0.036842  Acc: 98.000000\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 0.041761  Acc: 98.000000\n",
      "Train Epoch: 5 [32000/50000 (64%)]\tLoss: 0.042208  Acc: 98.000000\n",
      "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 0.041766  Acc: 98.000000\n",
      "Train Epoch: 5 [44800/50000 (90%)]\tLoss: 0.044350  Acc: 98.000000\n",
      "one epoch spend:  0:00:05.943294\n",
      "EPOCH:5, ACC:76.59\n",
      "\n",
      "Train Epoch: 6 [6400/50000 (13%)]\tLoss: 0.041676  Acc: 98.000000\n",
      "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 0.037842  Acc: 98.000000\n",
      "Train Epoch: 6 [19200/50000 (38%)]\tLoss: 0.035791  Acc: 98.000000\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 0.033934  Acc: 98.000000\n",
      "Train Epoch: 6 [32000/50000 (64%)]\tLoss: 0.033672  Acc: 98.000000\n",
      "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 0.033656  Acc: 98.000000\n",
      "Train Epoch: 6 [44800/50000 (90%)]\tLoss: 0.034781  Acc: 98.000000\n",
      "one epoch spend:  0:00:05.996527\n",
      "EPOCH:6, ACC:75.71\n",
      "\n",
      "Train Epoch: 7 [6400/50000 (13%)]\tLoss: 0.016009  Acc: 99.000000\n",
      "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 0.016659  Acc: 99.000000\n",
      "Train Epoch: 7 [19200/50000 (38%)]\tLoss: 0.024197  Acc: 99.000000\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 0.027435  Acc: 99.000000\n",
      "Train Epoch: 7 [32000/50000 (64%)]\tLoss: 0.028654  Acc: 99.000000\n",
      "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 0.032106  Acc: 98.000000\n",
      "Train Epoch: 7 [44800/50000 (90%)]\tLoss: 0.031503  Acc: 98.000000\n",
      "one epoch spend:  0:00:05.874051\n",
      "EPOCH:7, ACC:75.99\n",
      "\n",
      "Train Epoch: 8 [6400/50000 (13%)]\tLoss: 0.027152  Acc: 99.000000\n",
      "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 0.034620  Acc: 98.000000\n",
      "Train Epoch: 8 [19200/50000 (38%)]\tLoss: 0.032336  Acc: 98.000000\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 0.032472  Acc: 98.000000\n",
      "Train Epoch: 8 [32000/50000 (64%)]\tLoss: 0.033637  Acc: 98.000000\n",
      "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 0.033947  Acc: 98.000000\n",
      "Train Epoch: 8 [44800/50000 (90%)]\tLoss: 0.034665  Acc: 98.000000\n",
      "one epoch spend:  0:00:05.983404\n",
      "EPOCH:8, ACC:76.38\n",
      "\n",
      "Train Epoch: 9 [6400/50000 (13%)]\tLoss: 0.042331  Acc: 98.000000\n",
      "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 0.033812  Acc: 98.000000\n",
      "Train Epoch: 9 [19200/50000 (38%)]\tLoss: 0.031818  Acc: 98.000000\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 0.032032  Acc: 98.000000\n",
      "Train Epoch: 9 [32000/50000 (64%)]\tLoss: 0.030556  Acc: 99.000000\n",
      "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 0.031708  Acc: 98.000000\n",
      "Train Epoch: 9 [44800/50000 (90%)]\tLoss: 0.032053  Acc: 98.000000\n",
      "one epoch spend:  0:00:05.988966\n",
      "EPOCH:9, ACC:76.81\n",
      "\n",
      "Train Epoch: 10 [6400/50000 (13%)]\tLoss: 0.012914  Acc: 99.000000\n",
      "Train Epoch: 10 [12800/50000 (26%)]\tLoss: 0.014985  Acc: 99.000000\n",
      "Train Epoch: 10 [19200/50000 (38%)]\tLoss: 0.018159  Acc: 99.000000\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 0.021348  Acc: 99.000000\n",
      "Train Epoch: 10 [32000/50000 (64%)]\tLoss: 0.021111  Acc: 99.000000\n",
      "Train Epoch: 10 [38400/50000 (77%)]\tLoss: 0.022630  Acc: 99.000000\n",
      "Train Epoch: 10 [44800/50000 (90%)]\tLoss: 0.023354  Acc: 99.000000\n",
      "one epoch spend:  0:00:06.145769\n",
      "EPOCH:10, ACC:76.09\n",
      "\n",
      "Train Epoch: 11 [6400/50000 (13%)]\tLoss: 0.012233  Acc: 99.000000\n",
      "Train Epoch: 11 [12800/50000 (26%)]\tLoss: 0.017461  Acc: 99.000000\n",
      "Train Epoch: 11 [19200/50000 (38%)]\tLoss: 0.022310  Acc: 99.000000\n",
      "Train Epoch: 11 [25600/50000 (51%)]\tLoss: 0.024000  Acc: 99.000000\n",
      "Train Epoch: 11 [32000/50000 (64%)]\tLoss: 0.025939  Acc: 99.000000\n",
      "Train Epoch: 11 [38400/50000 (77%)]\tLoss: 0.027223  Acc: 99.000000\n",
      "Train Epoch: 11 [44800/50000 (90%)]\tLoss: 0.027057  Acc: 99.000000\n",
      "one epoch spend:  0:00:06.008217\n",
      "EPOCH:11, ACC:75.93\n",
      "\n",
      "Train Epoch: 12 [6400/50000 (13%)]\tLoss: 0.014860  Acc: 99.000000\n",
      "Train Epoch: 12 [12800/50000 (26%)]\tLoss: 0.014377  Acc: 99.000000\n",
      "Train Epoch: 12 [19200/50000 (38%)]\tLoss: 0.012531  Acc: 99.000000\n",
      "Train Epoch: 12 [25600/50000 (51%)]\tLoss: 0.011362  Acc: 99.000000\n",
      "Train Epoch: 12 [32000/50000 (64%)]\tLoss: 0.011690  Acc: 99.000000\n",
      "Train Epoch: 12 [38400/50000 (77%)]\tLoss: 0.013040  Acc: 99.000000\n",
      "Train Epoch: 12 [44800/50000 (90%)]\tLoss: 0.017317  Acc: 99.000000\n",
      "one epoch spend:  0:00:06.168676\n",
      "EPOCH:12, ACC:76.56\n",
      "\n",
      "Train Epoch: 13 [6400/50000 (13%)]\tLoss: 0.016064  Acc: 99.000000\n",
      "Train Epoch: 13 [12800/50000 (26%)]\tLoss: 0.016980  Acc: 99.000000\n",
      "Train Epoch: 13 [19200/50000 (38%)]\tLoss: 0.015054  Acc: 99.000000\n",
      "Train Epoch: 13 [25600/50000 (51%)]\tLoss: 0.016317  Acc: 99.000000\n",
      "Train Epoch: 13 [32000/50000 (64%)]\tLoss: 0.016609  Acc: 99.000000\n",
      "Train Epoch: 13 [38400/50000 (77%)]\tLoss: 0.016931  Acc: 99.000000\n",
      "Train Epoch: 13 [44800/50000 (90%)]\tLoss: 0.016823  Acc: 99.000000\n",
      "one epoch spend:  0:00:06.188729\n",
      "EPOCH:13, ACC:76.58\n",
      "\n",
      "Train Epoch: 14 [6400/50000 (13%)]\tLoss: 0.015911  Acc: 99.000000\n",
      "Train Epoch: 14 [12800/50000 (26%)]\tLoss: 0.011354  Acc: 99.000000\n",
      "Train Epoch: 14 [19200/50000 (38%)]\tLoss: 0.013110  Acc: 99.000000\n",
      "Train Epoch: 14 [25600/50000 (51%)]\tLoss: 0.015974  Acc: 99.000000\n",
      "Train Epoch: 14 [32000/50000 (64%)]\tLoss: 0.016824  Acc: 99.000000\n",
      "Train Epoch: 14 [38400/50000 (77%)]\tLoss: 0.018004  Acc: 99.000000\n",
      "Train Epoch: 14 [44800/50000 (90%)]\tLoss: 0.018772  Acc: 99.000000\n",
      "one epoch spend:  0:00:06.135087\n",
      "EPOCH:14, ACC:76.22\n",
      "\n",
      "Train Epoch: 15 [6400/50000 (13%)]\tLoss: 0.021792  Acc: 99.000000\n",
      "Train Epoch: 15 [12800/50000 (26%)]\tLoss: 0.018756  Acc: 99.000000\n",
      "Train Epoch: 15 [19200/50000 (38%)]\tLoss: 0.016833  Acc: 99.000000\n",
      "Train Epoch: 15 [25600/50000 (51%)]\tLoss: 0.016866  Acc: 99.000000\n",
      "Train Epoch: 15 [32000/50000 (64%)]\tLoss: 0.021813  Acc: 99.000000\n",
      "Train Epoch: 15 [38400/50000 (77%)]\tLoss: 0.020865  Acc: 99.000000\n",
      "Train Epoch: 15 [44800/50000 (90%)]\tLoss: 0.020514  Acc: 99.000000\n",
      "one epoch spend:  0:00:06.162090\n",
      "EPOCH:15, ACC:77.17\n",
      "\n",
      "Train Epoch: 16 [6400/50000 (13%)]\tLoss: 0.013485  Acc: 99.000000\n",
      "Train Epoch: 16 [12800/50000 (26%)]\tLoss: 0.013300  Acc: 99.000000\n",
      "Train Epoch: 16 [19200/50000 (38%)]\tLoss: 0.013198  Acc: 99.000000\n",
      "Train Epoch: 16 [25600/50000 (51%)]\tLoss: 0.013672  Acc: 99.000000\n",
      "Train Epoch: 16 [32000/50000 (64%)]\tLoss: 0.014376  Acc: 99.000000\n",
      "Train Epoch: 16 [38400/50000 (77%)]\tLoss: 0.015669  Acc: 99.000000\n",
      "Train Epoch: 16 [44800/50000 (90%)]\tLoss: 0.014941  Acc: 99.000000\n",
      "one epoch spend:  0:00:06.036296\n",
      "EPOCH:16, ACC:76.59\n",
      "\n",
      "Train Epoch: 17 [6400/50000 (13%)]\tLoss: 0.012282  Acc: 99.000000\n",
      "Train Epoch: 17 [12800/50000 (26%)]\tLoss: 0.011035  Acc: 99.000000\n",
      "Train Epoch: 17 [19200/50000 (38%)]\tLoss: 0.013924  Acc: 99.000000\n",
      "Train Epoch: 17 [25600/50000 (51%)]\tLoss: 0.018537  Acc: 99.000000\n",
      "Train Epoch: 17 [32000/50000 (64%)]\tLoss: 0.018049  Acc: 99.000000\n",
      "Train Epoch: 17 [38400/50000 (77%)]\tLoss: 0.017517  Acc: 99.000000\n",
      "Train Epoch: 17 [44800/50000 (90%)]\tLoss: 0.018199  Acc: 99.000000\n",
      "one epoch spend:  0:00:06.007593\n",
      "EPOCH:17, ACC:76.64\n",
      "\n",
      "Train Epoch: 18 [6400/50000 (13%)]\tLoss: 0.015374  Acc: 99.000000\n",
      "Train Epoch: 18 [12800/50000 (26%)]\tLoss: 0.013040  Acc: 99.000000\n",
      "Train Epoch: 18 [19200/50000 (38%)]\tLoss: 0.013739  Acc: 99.000000\n",
      "Train Epoch: 18 [25600/50000 (51%)]\tLoss: 0.017404  Acc: 99.000000\n",
      "Train Epoch: 18 [32000/50000 (64%)]\tLoss: 0.017491  Acc: 99.000000\n",
      "Train Epoch: 18 [38400/50000 (77%)]\tLoss: 0.016274  Acc: 99.000000\n",
      "Train Epoch: 18 [44800/50000 (90%)]\tLoss: 0.015322  Acc: 99.000000\n",
      "one epoch spend:  0:00:06.046363\n",
      "EPOCH:18, ACC:75.95\n",
      "\n",
      "Train Epoch: 19 [6400/50000 (13%)]\tLoss: 0.014555  Acc: 99.000000\n",
      "Train Epoch: 19 [12800/50000 (26%)]\tLoss: 0.011383  Acc: 99.000000\n",
      "Train Epoch: 19 [19200/50000 (38%)]\tLoss: 0.012924  Acc: 99.000000\n",
      "Train Epoch: 19 [25600/50000 (51%)]\tLoss: 0.018392  Acc: 99.000000\n",
      "Train Epoch: 19 [32000/50000 (64%)]\tLoss: 0.019308  Acc: 99.000000\n",
      "Train Epoch: 19 [38400/50000 (77%)]\tLoss: 0.018669  Acc: 99.000000\n",
      "Train Epoch: 19 [44800/50000 (90%)]\tLoss: 0.017671  Acc: 99.000000\n",
      "one epoch spend:  0:00:06.092607\n",
      "EPOCH:19, ACC:76.77\n",
      "\n",
      "Train Epoch: 20 [6400/50000 (13%)]\tLoss: 0.008880  Acc: 99.000000\n",
      "Train Epoch: 20 [12800/50000 (26%)]\tLoss: 0.006226  Acc: 99.000000\n",
      "Train Epoch: 20 [19200/50000 (38%)]\tLoss: 0.005472  Acc: 99.000000\n",
      "Train Epoch: 20 [25600/50000 (51%)]\tLoss: 0.007346  Acc: 99.000000\n",
      "Train Epoch: 20 [32000/50000 (64%)]\tLoss: 0.009202  Acc: 99.000000\n",
      "Train Epoch: 20 [38400/50000 (77%)]\tLoss: 0.010322  Acc: 99.000000\n",
      "Train Epoch: 20 [44800/50000 (90%)]\tLoss: 0.011563  Acc: 99.000000\n",
      "one epoch spend:  0:00:05.993856\n",
      "EPOCH:20, ACC:76.3\n",
      "\n",
      "CIFAR10 pytorch AlexNet Train: EPOCH:20, BATCH_SZ:64, LR:0.01, ACC:77.17\n",
      "train spend time:  0:02:13.108350\n"
     ]
    }
   ],
   "source": [
    "# 如果不训练，直接加载保存的网络参数进行测试集验证\n",
    "if notrain:\n",
    "    net.load_state_dict(t.load(PARAS_FN))\n",
    "    net_test(net, test_load, 0)\n",
    "\n",
    "else:\n",
    "    optimizer = optim.SGD(net.parameters(), lr=trainlr, momentum=mm)\n",
    "\n",
    "    start_time = datetime.datetime.now()\n",
    "\n",
    "    for epoch in range(1, ep + 1):\n",
    "        net_train(net, train_load, optimizer, epoch, logint)\n",
    "\n",
    "        # 每个epoch结束后用测试集检查识别准确度\n",
    "        net_test(net, test_load, epoch)\n",
    "\n",
    "        end_time = datetime.datetime.now()\n",
    "\n",
    "    global best_acc\n",
    "    #print('CIFAR10 pytorch LeNet Train: EPOCH:{}, BATCH_SZ:{}, LR:{}, ACC:{}'.format(args.epochs, args.batch_size, lr, best_acc))\n",
    "    print('CIFAR10 pytorch AlexNet Train: EPOCH:{}, BATCH_SZ:{}, LR:{}, ACC:{}'.format(ep, bs, trainlr, best_acc))\n",
    "    print('train spend time: ', end_time - start_time)\n",
    "\n",
    "    if savemodel:\n",
    "        t.save(net.state_dict(), PARAS_FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
